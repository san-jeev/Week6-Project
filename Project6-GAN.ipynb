# coding: utf-8

from __future__ import print_function, division
# Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano.
# Keras was developed with a focus on enabling fast experimentation.
# We will be training our GAN on the MNIST dataset
from keras.datasets import fashion_mnist
from keras.layers import Input, Dense, Reshape, Flatten, Dropout
from keras.layers.convolutional import UpSampling2D, Conv2D
from keras.models import Sequential, Model
from keras.optimizers import Adam
from keras.layers import BatchNormalization, Activation, ZeroPadding2D
from keras.layers.advanced_activations import LeakyReLU

# to plot and save our images as they are generated.
import matplotlib.pyplot as plt
import numpy as np
import sys


#A generative adversarial network (GAN) is a machine learning (ML) model in which two neural networks compete with each other to become more accurate in their predictions. GANs typically run unsupervised and use a cooperative zero-sum game framework to learn.
# A GAN has two parts in it: the generator that generates images and the discriminator that classifies real and fake images
# Both Generator and Discriminator are multilayer perceptrons (MLP).
# GAN is used to repair images and fill the missing part with created “content”.
# Generative models of time-series data can be used to simulate possible futures
# GANs are unsupervised learning algorithms that use a supervised loss as part of the training.
# Create a class called GAN
class GAN():
    def __init__(self):      #__init__ is the constructor for a class. The self parameter refers to the instance of the object
        self.img_rows = 28   # Image shape is (28,28,1)
        self.img_cols = 28
        self.channels = 1  # Channel layers allow to communicate between different instances of an application and processes for things like broadcast messaging -
        self.img_shape = (self.img_rows, self.img_cols, self.channels)
        self.latent_dim = 100  # Latent dimensionality of the encoding space, "latent_dim" is the number of nodes used as input of the generator

        # Adam is an optimization algorithm that can used instead of the classical stochastic gradient descent procedure to update network weights iterative based in training data.
        # alphe - Also referred to as the learning rate or step size. The proportion that weights are updated (e.g. 0.001). Larger values (e.g. 0.3) results in faster initial learning before the rate is updated. Smaller values (e.g. 1.0E-5) slow learning right down during training
        # beta1. The exponential decay rate for the first moment estimates (e.g. 0.9).
        # Initialize the optimizer
        optimizer = Adam(0.0002, 0.5)

        # Discriminator checks the validity of the images
        # Instantiate the discriminator by building and compiling the discriminator
        self.discriminator = self.build_discriminator()
        self.discriminator.compile(loss='binary_crossentropy',   # loss function is binary_crossentropy
            optimizer=optimizer,  # optimizer is Adam
            metrics=['accuracy'])  # metric function is used to judge the performance of your model.

        # Instantiate and build the generator using build_generator
        self.generator = self.build_generator()

        # In a GAN the Generator network takes noise z as an input to produce its images.
        # The generator takes noise as input and generates images
        z = Input(shape=(self.latent_dim,))
        # Get the generated image with noise as input
        img = self.generator(z)

        # For the combined model we will only train the generator. This ensures that when we combine our networks we only train the Generator.
        self.discriminator.trainable = False

        # Discriminator will take the images generated by our Generator and true dataset and set its output to a parameter called validity, which will indicate whether the input is real or not.
        # The discriminator takes generated images as input and determines validity
        validity = self.discriminator(img)

        # Here we combined the models and also set our loss function and optimizer. The ultimate goal here is for the Generator to fool the Discriminator.
        # Combined model: used to fool the discriminator with the generator
        # The combined model  (stacked generator and discriminator)
        # Trains the generator to fool the discriminator
        # z with the input shape (*, self.latent_dim) is the input to the generator and the generator's output is the input to the discriminator
        self.combined = Model(z, validity)
        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)

    # Noise is transformed into an image in the generator as following
    # Noise (100,1)  --dense--> 7x7xx256 --dense->  --dense--> (1024,1) --reshape--> (28,28,1)
    # Noise (100,1)  --dense--> (256,1) --dense-> (512,1) --dense--> (1024,1) --reshape--> (28,28,1)
    def build_generator(self):

        model = Sequential() # Sequential is the type of model we’ll be building. This will allow us to build our model layer by layer.

        model.add(Dense(256, input_dim=self.latent_dim)) # Dense layer with input of (self.latent_dim) and output of (*,256 units); Refers to Dense layers which are layers where every neuron of the previous layer is connected to every neuron of the next input layer.
        model.add(LeakyReLU(alpha=0.2)) # Leaky ReLU layer applies this function to incoming data; alpha is a hyperparameter which controls the underlying value to which the function saturates negatives network inputs.
        model.add(BatchNormalization(momentum=0.8))  # Batch normalization to normalize data...This will allow us to train on a more stable distribution of inputs. This is achieved through standardizing our inputs to have a mean of 0 and a standard deviation of 1.
        model.add(Dense(512))  # Dense layer with output of (*,512 units)
        model.add(LeakyReLU(alpha=0.2))
        model.add(BatchNormalization(momentum=0.8))  #Batch Normalization; momentum is a technique used in Neural Networks to speed up the training speed and improve accuracy.
        model.add(Dense(1024))   # Dense layer of (*, 1024)
        model.add(LeakyReLU(alpha=0.2))   #  Leaky ReLU is a type of activation function which essentially transform any input signal to an output signal for the next layer.
        model.add(BatchNormalization(momentum=0.8))    # Batch Normalization
        #model.add(Dense(2048))
        #model.add(LeakyReLU(alpha=0.2))
        #model.add(BatchNormalization(momentum=0.8))
        model.add(Dense(np.prod(self.img_shape), activation='tanh'))    # Dense layer of size (*, 256) with activation tanh
        model.add(Reshape(self.img_shape))   # Reshape back to img_shape, Helps us reshape the output of a layer to a specific shape.

        model.summary()

        noise = Input(shape=(self.latent_dim,))   # Add some noice to model of type shape = (self.latent_dim,)
        img = model(noise)

        return Model(noise, img)


    # Given an input image from generator, the Discriminator outputs the likelihood of the image being real
    def build_discriminator(self):

        model = Sequential()

        model.add(Flatten(input_shape=self.img_shape)) # First layer of discriminator is to flatten the input_shape of 28,28,1. Allows us to flatten the input by removing all of its dimensions except for 1. It’s essentially the operation of converting a Matrix into a simple array.
        model.add(Dense(512)) # Add a dense layer with an output (*, 512)
        model.add(LeakyReLU(alpha=0.2))  # Add an activation function of Leaky ReLU
        model.add(Dense(256)) # Add another dense layer, which outputs (*,256)
        model.add(LeakyReLU(alpha=0.2))  # Add another activation function of leaky ReLU
        model.add(Dense(1, activation='sigmoid'))  # Add a final output of (*,1) with activation sigmoid
        model.summary()

        img = Input(shape=self.img_shape)
        validity = model(img)   # The validity is the Discriminator’s guess in respect to the input image’s likelihood of being real or not.

        return Model(img, validity)


    # Pit the two models (Generator and Discriminator) against each other by defining a training function, loading the data set, re-scaling our training images and setting the ground truths.
    # For each iteration of the epoch do the following:
    # - Select a random batch of images
    # - Generate images
    # - Calculate the loss for real and fake images
    #  Sample and plot the images
    def train(self, epochs, batch_size=128, sample_interval=50):  #Number of epochs to train for and batch size for training

        # Load the dataset
        (X_train, _), (_, _) = fashion_mnist.load_data()

        # Rescale -1 to 1
        X_train = X_train / 127.5 - 1.
        X_train = np.expand_dims(X_train, axis=3)

        # Adversarial ground truths
        valid = np.ones((batch_size, 1))
        fake = np.zeros((batch_size, 1))


        # Loop through a number of epochs to train our Discriminator by first selecting a random batch of images from our true dataset,
        # generating a set of images from our Generator, feeding both set of images into our Discriminator,
        # and finally setting the loss parameters for both the real and fake images, as well as the combined loss.

        for epoch in range(epochs):

            # ---------------------
            #  Train Discriminator
            # ---------------------

            # Select a random batch of images
            idx = np.random.randint(0, X_train.shape[0], batch_size)
            imgs = X_train[idx]

            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))

            # Generate a batch of new images
            gen_imgs = self.generator.predict(noise)

            # Train the discriminator
            d_loss_real = self.discriminator.train_on_batch(imgs, valid)
            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)
            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)


            # ---------------------
            #  Train Generator
            # ---------------------

            # Train Generator, by setting the input noise and ultimately training the Generator to have the Discriminator label its samples as valid by specifying the gradient loss.
            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))

            # Train the generator (to have the discriminator label samples as valid)
            g_loss = self.combined.train_on_batch(noise, valid)




            # to keep track of our training process, we print the progress and save the sample image output depending on the epoch interval specified.
            # Plot the progress
            print ("%d [D loss: %f, acc.: %.2f%%] [G loss: %f]" % (epoch, d_loss[0], 100*d_loss[1], g_loss))

            # If at save interval => save generated image samples
            if epoch % sample_interval == 0:
                self.sample_images(epoch)

    # When the specific sample_interval is hit, we call the sample_image function
    # This function saves our images for us to view
    def sample_images(self, epoch):
        r, c = 5, 5
        noise = np.random.normal(0, 1, (r * c, self.latent_dim))
        gen_imgs = self.generator.predict(noise)

        # Rescale images 0 - 1
        gen_imgs = 0.5 * gen_imgs + 0.5

        fig, axs = plt.subplots(r, c)
        cnt = 0
        for i in range(r):
            for j in range(c):
                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')
                axs[i,j].axis('off')
                cnt += 1
        #fig.savefig("images/%d.png" % epoch)
        plt.show()
        plt.close()


# In[ ]:

# Call original GAN class and pass in the expected parameters.
# Epochs dictate the number of backward and forward propagations
# batch_size indicates the number of training samples per backward/forward propagation
# sample_interval specifies after how many epochs we call our sample_image function.
if __name__ == '__main__':
    gan = GAN()
    gan.train(epochs=3000, batch_size=32, sample_interval=200)

